name: Run Tests

on:
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]

concurrency:
  group: pr-tests-${{ github.event.pull_request.head.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  pull-requests: write

jobs:
  pytest:
    runs-on: ubuntu-latest
    env:
      PYTHONPATH: "${{ github.workspace }}:${{ github.workspace }}/src:${{ github.workspace }}/tests"
    steps:
      - uses: actions/checkout@v6

      - uses: actions/setup-python@v6
        with:
          python-version: "3.13"

      - name: Install requirements
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Run tests
        run: |
          set -o pipefail
          pytest --cov=src \
                --cov-branch \
                --cov-report=xml \
                --cov-report=term-missing \
                --cov-report=html \
                | tee pytest-output.log

      - name: Append test & coverage summary to job summary
        if: always()
        run: |
          echo "## Pytest Summary" >> "$GITHUB_STEP_SUMMARY"
          # grab the last line with the totals (e.g. '46 passed, 2 failed...')
          tail -n 20 pytest-output.log | sed -n '/^=*=*/p' >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"

          echo "## Test Coverage" >> "$GITHUB_STEP_SUMMARY"
          echo '```' >> "$GITHUB_STEP_SUMMARY"
          coverage report >> "$GITHUB_STEP_SUMMARY"
          echo '```' >> "$GITHUB_STEP_SUMMARY"

      - name: Upload test & coverage artifacts
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: test-report
          path: |
            htmlcov
            pytest-output.log
            coverage.xml

      - uses: actions/github-script@v8
        if: always()
        with:
          github-token: ${{ github.token }}
          script: |
            const marker = '<!-- mb-coverage-comment -->';

            // coverage summary
            const { stdout: covStdout } = await exec.getExecOutput('coverage', [
              'report',
              '--show-missing',
            ]);

            // pytest summary: last line with the "X passed, Y failed..." stuff
            const fs = require('fs');
            const log = fs.readFileSync('pytest-output.log', 'utf8').split('\n');
            const summaryLine = log.reverse().find(line => line.startsWith('=') && line.includes('passed'));

            const body = [
              marker,
              '### âœ… Test & Coverage Summary',
              '',
              summaryLine ? `**Pytest:** \`${summaryLine.trim()}\`` : '**Pytest:** (summary not found)',
              '',
              '```text',
              covStdout.trim(),
              '```',
            ].join('\n');

            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              per_page: 100,
            });

            const existing = comments.reverse().find(c => c.body && c.body.includes(marker));

            if (existing) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existing.id,
                body,
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body,
              });
            }
